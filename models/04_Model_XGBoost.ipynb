{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9d6cd1e",
   "metadata": {},
   "source": [
    "\n",
    "# 04. XGBoost ê³ ë„í™” ë° í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”\n",
    "\n",
    "ë³¸ ë…¸íŠ¸ë¶ì€ **XGBoost (eXtreme Gradient Boosting)** ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•œ ì˜ˆì¸¡ ëª¨ë¸ë§ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "ëŒ€ìš©ëŸ‰ ë°ì´í„°ì˜ ë¹ ë¥¸ ì²˜ë¦¬ë¥¼ ìœ„í•´ Histogram-based ê³µë²•ì„ ì‚¬ìš©í•˜ë©°, Optuna ìŠ¤íƒ€ì¼ì˜ íŒŒë¼ë¯¸í„° íŠœë‹ ê°œë…ì„ ì ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ğŸ§© ì£¼ìš” ì „ëµ\n",
    "1. **Data Efficient Loading**: í•„ìš” ì»¬ëŸ¼ ìœ„ì£¼ì˜ ë¡œë”© ë° ë©”ëª¨ë¦¬ ìµœì í™”\n",
    "2. **Advanced Feature Engineering**:\n",
    "    - ë°©ë¬¸ ì‹œí€€ìŠ¤ ë‚´ì˜ ì•„ì´í…œ(Item)ë³„ í´ë¦­ í™•ë¥ (Click Probability) ë§¤í•‘\n",
    "    - ë³µí•© ìƒí˜¸ì‘ìš© ë³€ìˆ˜(Cross Product Features) ìƒì„±\n",
    "3. **Training & Optimization**:\n",
    "    - `tree_method='hist'` ì„¤ì •ì„ í†µí•œ í•™ìŠµ ì†ë„ ê°œì„ \n",
    "    - LogLoss ìµœì†Œí™”ë¥¼ ìœ„í•œ ì¡°ê¸° ì¢…ë£Œ(Early Stopping) ê¸°ë²• ì ìš©\n",
    "4. **Result Aggregation**: ì‹œë“œë³„ ì˜ˆì¸¡ ê²°ê³¼ì˜ í‰ê· (Mean)ì„ ì‚¬ìš©í•œ ì•ˆì •ì  ì¶”ë¡ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d86cfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import os\n",
    "import random\n",
    "import gc\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score, log_loss\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f5c6a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Path: ../rawdata\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class CFG:\n",
    "    DATA_PATH = '../rawdata'\n",
    "    SEEDS = [42, 106, 1031]\n",
    "    # ì „ì²´ ë°ì´í„° ì‚¬ìš© ì‹œì—” 10, í•™ìŠµ ì†ë„ë¥¼ ìœ„í•´ 1ë¡œ ì„¤ì • ê°€ëŠ¥\n",
    "    # ì—¬ê¸°ì„œëŠ” 1:1 ë¹„ìœ¨ ì‚¬ìš©\n",
    "    NEG_RATIO = 1 \n",
    "    \n",
    "    # XGBoost íŒŒë¼ë¯¸í„° (ì¼ë°˜ì ì¸ íŠœë‹ ê°’)\n",
    "    XGB_PARAMS = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'logloss',\n",
    "        'learning_rate': 0.05,\n",
    "        'max_depth': 8,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'n_estimators': 100,  # Optimized for faster demo,\n",
    "        'early_stopping_rounds': 10,\n",
    "        'tree_method': 'hist', # GPUê°€ ìˆë‹¤ë©´ 'gpu_hist' ë¡œ ë³€ê²½\n",
    "        'device': 'cpu'        # GPUê°€ ìˆë‹¤ë©´ 'cuda' ë¡œ ë³€ê²½\n",
    "    }\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "print(f\"Data Path: {CFG.DATA_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0eadc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Click Probability Map ë¡œë“œ\n",
    "try:\n",
    "    df_click_prob = pd.read_excel(os.path.join(CFG.DATA_PATH, 'high_click_numbers.xlsx'))\n",
    "    click_prob_map = dict(zip(df_click_prob['number'], df_click_prob['click_prob']))\n",
    "except:\n",
    "    click_prob_map = {}\n",
    "\n",
    "# 2. Seq Feature ìƒì„± í•¨ìˆ˜\n",
    "pos_list = {370, 528, 68, 561, 144, 227, 417, 442, 186, 395}\n",
    "neg_list = {154, 222, 84, 498, 434, 511, 216, 497, 309, 446}\n",
    "\n",
    "def add_seq_features(df):\n",
    "    seq_len, avg_prob, seq_neg, seq_pos = [], [], [], []\n",
    "    for s in df[\"seq\"]:\n",
    "        if isinstance(s, str) and s != \"\":\n",
    "            arr = [int(x) for x in s.split(\",\") if x]\n",
    "            seq_len.append(len(arr))\n",
    "            probs = [click_prob_map.get(num, 0) for num in arr]\n",
    "            avg_prob.append(sum(probs) / len(probs) if probs else 0)\n",
    "            seq_neg.append(sum(1 for x in arr if x in neg_list))\n",
    "            seq_pos.append(sum(1 for x in arr if x in pos_list))\n",
    "        else:\n",
    "            seq_len.append(0)\n",
    "            avg_prob.append(0)\n",
    "            seq_neg.append(0)\n",
    "            seq_pos.append(0)\n",
    "            \n",
    "    df[\"seq_len\"] = seq_len\n",
    "    df[\"avg_click_prob\"] = avg_prob\n",
    "    df[\"seq_neglogcount\"] = seq_neg\n",
    "    df[\"seq_poslogcount\"] = seq_pos\n",
    "    return df\n",
    "\n",
    "# 3. Interaction Feature ìƒì„± í•¨ìˆ˜\n",
    "def add_interaction_features(df):\n",
    "    cols = ['gender', 'age_group', 'inventory_id', 'day_of_week', 'hour']\n",
    "    for col1, col2 in combinations(cols, 2):\n",
    "        new_col = f'{col1}_{col2}'\n",
    "        df[new_col] = df[col1].astype(str) + '_' + df[col2].astype(str)\n",
    "        df[new_col] = df[new_col].astype('category')\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_groupby_features(train_df, test_df, feature_name, agg_dict):\n",
    "    # Group Statistics\n",
    "    agg_stats = train_df.groupby(feature_name).agg(agg_dict)\n",
    "    new_cols = [f\"{feature_name}_{col[0]}_{col[1]}\" for col in agg_stats.columns]\n",
    "    agg_stats.columns = new_cols\n",
    "    agg_stats.reset_index(inplace=True)\n",
    "\n",
    "    train_df = pd.merge(train_df, agg_stats, on=feature_name, how='left')\n",
    "    test_df = pd.merge(test_df, agg_stats, on=feature_name, how='left')\n",
    "    \n",
    "    # Fill NAs in new columns with mean\n",
    "    for col in new_cols:\n",
    "        fill_val = train_df[col].mean()\n",
    "        test_df[col] = test_df[col].fillna(fill_val)\n",
    "    return train_df, test_df\n",
    "\n",
    "def add_count_features(train_df, test_df, count_cols):\n",
    "    # Count Encoding\n",
    "    for col in count_cols:\n",
    "        all_data = pd.concat([train_df[col], test_df[col]], ignore_index=True)\n",
    "        count_map = all_data.value_counts().to_dict()\n",
    "        train_df[f\"{col}_count\"] = train_df[col].map(count_map).fillna(0).astype(int)\n",
    "        test_df[f\"{col}_count\"] = test_df[col].map(count_map).fillna(0).astype(int)\n",
    "    return train_df, test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77cbdf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "ğŸš€ Processing Seed: 42\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prediction_files = []\n",
    "\n",
    "for seed in CFG.SEEDS:\n",
    "    print(f\"\\n{'='*30}\\nğŸš€ Processing Seed: {seed}\\n{'='*30}\")\n",
    "    seed_everything(seed)\n",
    "    \n",
    "    # 1. Load Data\n",
    "    train_path = os.path.join(CFG.DATA_PATH, 'train_sample_10pct.parquet')\n",
    "    train_df = pd.read_parquet(train_path)\n",
    "    \n",
    "    try:\n",
    "        test_df = pd.read_parquet(os.path.join(CFG.DATA_PATH, 'test.parquet'))\n",
    "    except:\n",
    "        # Dummy for demo\n",
    "        test_df = train_df.head(100).drop(columns=['clicked'])\n",
    "        test_df['ID'] = [f'TEST_{i}' for i in range(100)] \n",
    "        \n",
    "    # 2. Down-sampling\n",
    "    print(\"ğŸ”» Down-sampling...\")\n",
    "    clicked_1 = train_df[train_df['clicked'] == 1]\n",
    "    n_neg = int(len(clicked_1) * CFG.NEG_RATIO)\n",
    "    clicked_0 = train_df[train_df['clicked'] == 0].sample(n=n_neg, random_state=seed)\n",
    "    train_df = pd.concat([clicked_1, clicked_0], axis=0).sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "    \n",
    "    # 3. Feature Engineering\n",
    "    print(\"ğŸ› ï¸ Feature Engineering...\")\n",
    "    train_df = add_seq_features(train_df)\n",
    "    test_df = add_seq_features(test_df)\n",
    "    \n",
    "    train_df = add_interaction_features(train_df)\n",
    "    test_df = add_interaction_features(test_df)\n",
    "\n",
    "    # --- Added Missing Logic ---\n",
    "    # 3.1 Groupby Features\n",
    "    aggs = {\n",
    "        'history_a_1': ['mean', 'std'], 'history_a_2': ['mean', 'std'], \n",
    "        'history_a_3': ['mean', 'std'], 'feat_d_4': ['mean', 'std']\n",
    "    }\n",
    "    train_df, test_df = add_groupby_features(train_df, test_df, 'inventory_id', aggs)\n",
    "    \n",
    "    # 3.2 Count Encoding\n",
    "    count_targets = ['age_group', 'inventory_id', 'day_of_week'] \n",
    "    # train_df, test_df = add_count_features(train_df, test_df, count_targets) # XGBoostëŠ” ì¹´ìš´íŠ¸ ì •ë³´ë¥¼ ëœ íƒ€ê¸°ë„ í•˜ì§€ë§Œ ì¶”ê°€ ê¶Œì¥\n",
    "    # ---------------------------\n",
    "\n",
    "    \n",
    "    \n",
    "    # 4. Preprocessing for XGBoost (Category to Code)\n",
    "    # XGBoost handles categories, but simple coding is safer for hist\n",
    "    cat_cols = train_df.select_dtypes(include=['object', 'category']).columns\n",
    "    for col in cat_cols:\n",
    "        train_df[col] = train_df[col].astype('category')\n",
    "        test_df[col] = test_df[col].astype('category')\n",
    "        \n",
    "    # 5. Training\n",
    "    print(\"ğŸ”¥ Training XGBoost...\")\n",
    "    features = [c for c in train_df.columns if c not in ['clicked', 'ID', 'seq', 'seq_length']] # seq_lengthëŠ” ì œì™¸? ìœ ì§€? -> ìœ ì§€\n",
    "    # seq ì»¬ëŸ¼ì€ ë¬¸ìì—´ì´ë¼ ì œì™¸ í•„ìˆ˜\n",
    "    features = [c for c in features if c != 'seq']\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        train_df[features], train_df['clicked'], \n",
    "        test_size=0.2, random_state=seed, stratify=train_df['clicked']\n",
    "    )\n",
    "    \n",
    "    # enable_categorical=True required for category dtype\n",
    "    model = xgb.XGBClassifier(**CFG.XGB_PARAMS, enable_categorical=True, random_state=seed)\n",
    "    \n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        verbose=100\n",
    "    )\n",
    "    \n",
    "    # 6. Prediction\n",
    "    preds = model.predict_proba(test_df[features])[:, 1]\n",
    "    \n",
    "    out_file = f\"04_XGBoost_{seed}.csv\"\n",
    "    if 'ID' in test_df.columns:\n",
    "        sub = pd.DataFrame({'ID': test_df['ID'], 'clicked': preds})\n",
    "    else:\n",
    "        sub = pd.DataFrame({'ID': range(len(preds)), 'clicked': preds})\n",
    "        \n",
    "    sub.to_csv(out_file, index=False)\n",
    "    prediction_files.append(out_file)\n",
    "    print(f\"âœ… Saved: {out_file}\")\n",
    "    \n",
    "    del train_df, X_train, X_val, model\n",
    "    gc.collect()\n",
    "\n",
    "print(\"\\nğŸ All seeds processed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21158eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Soft Voting\n",
    "print(f\"\\nğŸ¤ Soft Voting: {prediction_files}\")\n",
    "if prediction_files:\n",
    "    merged = pd.read_csv(prediction_files[0]).rename(columns={'clicked': 'click_0'})\n",
    "    for i, f in enumerate(prediction_files[1:], 1):\n",
    "        d = pd.read_csv(f).rename(columns={'clicked': f'click_{i}'})\n",
    "        merged = merged.merge(d, on='ID')\n",
    "        \n",
    "    cols = [c for c in merged.columns if c.startswith('click_')]\n",
    "    merged['clicked'] = merged[cols].mean(axis=1)\n",
    "    \n",
    "    merged[['ID', 'clicked']].to_csv('04_XGBoost_SoftVoting.csv', index=False)\n",
    "    print(\"ğŸ‰ Final XGBoost Ensemble Saved: xgb.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
