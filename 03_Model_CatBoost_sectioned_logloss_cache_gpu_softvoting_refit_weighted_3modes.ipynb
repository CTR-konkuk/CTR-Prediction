{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c101ac46",
   "metadata": {},
   "source": [
    "# CatBoost OOF + SoftVoting Ensemble (GPU ì§€ì›) â€” Logloss í•™ìŠµ + Global FE ìºì‹± + 10%/50%/Full ëª¨ë“œ\n",
    "\n",
    "ì‹¤í–‰ ìˆœì„œ: **[0] ì„¤ì •/ìƒìˆ˜ â†’ [1] ìœ í‹¸ â†’ [2] FE ìºì‹œ â†’ [3] OOF í•™ìŠµ/seed ì˜ˆì¸¡ â†’ [4] SoftVoting/í‰ê°€**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c28af7",
   "metadata": {},
   "source": [
    "## [0] ì„¤ì • / ìƒìˆ˜ (ë¨¼ì € ì‹¤í–‰)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7160ae9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… CFG: FULL | folds: 5 | seeds: [42, 106, 1031] | GPU: True 0-1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "class CFG:\n",
    "    DATA_PATH = \"/home/konkukstat/python3/workspace/data\"\n",
    "    CACHE_SUBDIR = \"_cache_fe\"\n",
    "    OUTPUT_DIR = \"./outputs\"\n",
    "    \n",
    "    TRAIN_FULL_FILE = \"train.parquet\"\n",
    "    TRAIN_10_FILE = \"train_sample_10pct.parquet\"\n",
    "    TRAIN_50_FILE = \"train_sampled_50pct.parquet\"\n",
    "    TEST_FILE = \"test.parquet\"\n",
    "\n",
    "    TRAIN_MODE = \"FULL\"\n",
    "    SAMPLE_SEED = 42\n",
    "\n",
    "    N_SPLITS = 5\n",
    "    SEEDS = [42, 106, 1031]\n",
    "    SEED_WEIGHTS = None   # âœ… ì¶”ê°€ (Noneì´ë©´ ê· ë“± í‰ê· )\n",
    "    TEST_LABEL_FILE = None\n",
    "    \n",
    "    OUTPUT_PREFIX = \"CB\"\n",
    "\n",
    "    # ---- CatBoost Params ----\n",
    "    CB_ITERATIONS = 2000\n",
    "    CB_LEARNING_RATE = 0.05\n",
    "    CB_DEPTH = 7\n",
    "    CB_L2 = 20\n",
    "    CB_RANDOM_STRENGTH = 1.0\n",
    "    CB_SUBSAMPLE = 0.8\n",
    "\n",
    "    USE_GPU = True\n",
    "    GPU_DEVICES = \"0-1\"\n",
    "    \n",
    "    # =========================\n",
    "    # Refit Settings\n",
    "    # =========================\n",
    "    REFIT_ITERS_MIN = 300\n",
    "    REFIT_ITERS_MAX = 5000\n",
    "    REFIT_RECOMPUTE_TE = True   # full-train ê¸°ì¤€ TE ë‹¤ì‹œ ê³„ì‚° ì—¬ë¶€\n",
    "\n",
    "print(\"âœ… CFG:\", CFG.TRAIN_MODE, \"| folds:\", CFG.N_SPLITS, \"| seeds:\", CFG.SEEDS, \"| GPU:\", CFG.USE_GPU, CFG.GPU_DEVICES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a53871",
   "metadata": {},
   "source": [
    "## [1] ë¼ì´ë¸ŒëŸ¬ë¦¬ / ìœ í‹¸ í•¨ìˆ˜ (ë¨¼ì € ì‹¤í–‰)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7451887c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… utilities loaded\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import gc, random, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import average_precision_score, log_loss\n",
    "\n",
    "import catboost as cb\n",
    "\n",
    "EPS = 1e-15\n",
    "\n",
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "def toss_score(y_true, y_pred, eps=1e-15):\n",
    "    '''\n",
    "    Temporary Toss definition.\n",
    "    Replace with your exact competition/project Toss if needed.\n",
    "    Current: 0.5*AP + 0.5*(1/(1+Logloss))\n",
    "    '''\n",
    "    y_pred = np.clip(np.asarray(y_pred, dtype=float), eps, 1-eps)\n",
    "    ap = float(average_precision_score(y_true, y_pred))\n",
    "    ll = float(log_loss(y_true, y_pred))\n",
    "    return 0.5*ap + 0.5*(1.0/(1.0+ll))\n",
    "\n",
    "def add_cat_crosses(train_df: pd.DataFrame, test_df: pd.DataFrame, pairs):\n",
    "    for a, b in pairs:\n",
    "        if a in train_df.columns and b in train_df.columns and a in test_df.columns and b in test_df.columns:\n",
    "            new = f\"{a}__x__{b}\"\n",
    "            train_df[new] = train_df[a].astype(str) + \"_\" + train_df[b].astype(str)\n",
    "            test_df[new]  = test_df[a].astype(str)  + \"_\" + test_df[b].astype(str)\n",
    "    return train_df, test_df\n",
    "\n",
    "def add_count_features(train_df: pd.DataFrame, test_df: pd.DataFrame, cols, use_test_in_counts=True):\n",
    "    for c in cols:\n",
    "        if c not in train_df.columns or c not in test_df.columns:\n",
    "            continue\n",
    "        all_series = pd.concat([train_df[c], test_df[c]]) if use_test_in_counts else train_df[c]\n",
    "        vc = all_series.astype(str).value_counts(dropna=False)\n",
    "        new = f\"{c}__cnt\"\n",
    "        train_df[new] = train_df[c].astype(str).map(vc).astype(np.float32)\n",
    "        test_df[new]  = test_df[c].astype(str).map(vc).astype(np.float32)\n",
    "    return train_df, test_df\n",
    "\n",
    "def add_seq_features(df: pd.DataFrame, mode: str, fill_stats=None):\n",
    "    # df ì „ì²´ copy í•˜ì§€ ë§ê³ , ìƒˆ ì»¬ëŸ¼ë§Œ ì¶”ê°€(ì›ë³¸ì„ ë°”ê¾¸ê³  ì‹¶ì§€ ì•Šë‹¤ë©´ df = df.copy(deep=False) ì •ë„ë§Œ)\n",
    "    out = df  # in-placeë¡œ ë¶™ì´ëŠ” ë²„ì „ (ê°€ìž¥ ë©”ëª¨ë¦¬ ì ˆì•½)\n",
    "    # out = df.copy(deep=False)  # ì›ë³¸ ë³´í˜¸ê°€ í•„ìš”í•˜ë©´ ì´ ì •ë„ë§Œ\n",
    "\n",
    "    if \"seq\" in out.columns:\n",
    "        s = out[\"seq\"]\n",
    "\n",
    "        # ê²°ì¸¡ë§Œ ì²˜ë¦¬: astype(str) ì „ì²´ ë³€í™˜ì€ ë¹„ìŒˆ.\n",
    "        # ë¬¸ìžì—´ì´ ì•„ë‹Œ ê°’ì´ ì„žì—¬ìžˆì„ ìˆ˜ ìžˆì–´ ì•ˆì „í•˜ê²Œ ë¬¸ìžì—´í™”ëŠ” í•˜ë˜, NAë§Œ ë¨¼ì € ì±„ìš°ê³  ë³€í™˜\n",
    "        s2 = s.fillna(\"\").astype(\"string\")  # pandas StringDtype (objectë³´ë‹¤ ë³´í†µ ì•ˆì •ì )\n",
    "\n",
    "        # split ëŒ€ì‹  partition / rpartition (ë¦¬ìŠ¤íŠ¸ ìƒì„± ë°©ì§€)\n",
    "        # ì²« í† í°: 'a,b,c' -> 'a'\n",
    "        first = s2.str.partition(\",\")[0]\n",
    "        # ë§ˆì§€ë§‰ í† í°: 'a,b,c' -> 'c'\n",
    "        last  = s2.str.rpartition(\",\")[2]\n",
    "\n",
    "        seq_first = pd.to_numeric(first, errors=\"coerce\").astype(\"float32\")\n",
    "        seq_last  = pd.to_numeric(last,  errors=\"coerce\").astype(\"float32\")\n",
    "    else:\n",
    "        seq_first = pd.Series(np.nan, index=out.index, dtype=\"float32\")\n",
    "        seq_last  = pd.Series(np.nan, index=out.index, dtype=\"float32\")\n",
    "\n",
    "    if fill_stats is None:\n",
    "        m1 = float(seq_first.mean(skipna=True))\n",
    "        m2 = float(seq_last.mean(skipna=True))\n",
    "        if not np.isfinite(m1): m1 = 0.0\n",
    "        if not np.isfinite(m2): m2 = 0.0\n",
    "        fill_stats = {\"seq_first_num_mean\": m1, \"seq_last_num_mean\": m2}\n",
    "\n",
    "    out[\"seq_first_num\"] = seq_first.fillna(fill_stats[\"seq_first_num_mean\"]).astype(\"float32\")\n",
    "    out[\"seq_last_num\"]  = seq_last.fillna(fill_stats[\"seq_last_num_mean\"]).astype(\"float32\")\n",
    "\n",
    "    return out, fill_stats\n",
    "\n",
    "def add_oof_target_encoding(train_df: pd.DataFrame, test_df: pd.DataFrame, y, cols, folds, smoothing=20.0, noise=0.0, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    y = np.asarray(y).astype(float)\n",
    "    global_mean = float(np.mean(y))\n",
    "\n",
    "    if \"clicked\" not in train_df.columns:\n",
    "        raise KeyError(\"train_df must include 'clicked' for TE.\")\n",
    "\n",
    "    for c in cols:\n",
    "        if c not in train_df.columns or c not in test_df.columns:\n",
    "            continue\n",
    "\n",
    "        te_col = f\"{c}__te\"\n",
    "        train_te = np.zeros(len(train_df), dtype=np.float32)\n",
    "\n",
    "        for tr_idx, va_idx in folds:\n",
    "            tr = train_df.iloc[tr_idx]\n",
    "            va = train_df.iloc[va_idx]\n",
    "            stats = tr.groupby(c)[\"clicked\"].agg([\"mean\", \"count\"])\n",
    "            means = stats[\"mean\"]\n",
    "            cnts  = stats[\"count\"]\n",
    "            smooth = (means*cnts + global_mean*smoothing) / (cnts + smoothing)\n",
    "\n",
    "            mapped = va[c].map(smooth).fillna(global_mean).astype(np.float32).values\n",
    "            if noise > 0:\n",
    "                mapped = mapped * (1.0 + rng.normal(0, noise, size=len(mapped))).astype(np.float32)\n",
    "            train_te[va_idx] = mapped\n",
    "\n",
    "        stats_full = train_df.groupby(c)[\"clicked\"].agg([\"mean\", \"count\"])\n",
    "        means = stats_full[\"mean\"]\n",
    "        cnts  = stats_full[\"count\"]\n",
    "        smooth_full = (means*cnts + global_mean*smoothing) / (cnts + smoothing)\n",
    "        test_te = test_df[c].map(smooth_full).fillna(global_mean).astype(np.float32).values\n",
    "\n",
    "        train_df[te_col] = train_te\n",
    "        test_df[te_col]  = test_te\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "def make_groupby_stats(source_df: pd.DataFrame, key: str, agg_dict: dict):\n",
    "    usable = {k: v for k, v in agg_dict.items() if k in source_df.columns}\n",
    "    if key not in source_df.columns or len(usable) == 0:\n",
    "        return None\n",
    "    stats = source_df.groupby(key).agg(usable)\n",
    "    stats.columns = [f\"{key}_{a}_{b}\" for (a, b) in stats.columns]\n",
    "    stats = stats.reset_index()\n",
    "    return stats\n",
    "\n",
    "def merge_groupby_stats(df: pd.DataFrame, stats: pd.DataFrame, key: str, fill_from_df: pd.DataFrame):\n",
    "    if stats is None:\n",
    "        return df\n",
    "    df = df.merge(stats, on=key, how=\"left\")\n",
    "    new_cols = [c for c in stats.columns if c != key]\n",
    "    for c in new_cols:\n",
    "        m = float(np.nanmean(fill_from_df[c].values)) if c in fill_from_df.columns else 0.0\n",
    "        if not np.isfinite(m):\n",
    "            m = 0.0\n",
    "        df[c] = df[c].fillna(m)\n",
    "    return df\n",
    "\n",
    "def print_gpu_info():\n",
    "    try:\n",
    "        import subprocess\n",
    "        out = subprocess.check_output(\"nvidia-smi -L\", shell=True).decode()\n",
    "        lines = [ln for ln in out.splitlines() if ln.strip()]\n",
    "        print(\"âœ… GPUs detected:\", len(lines))\n",
    "        print(out)\n",
    "    except Exception as e:\n",
    "        print(\"âš ï¸ nvidia-smi not available:\", e)\n",
    "\n",
    "print(\"âœ… utilities loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3455662",
   "metadata": {},
   "source": [
    "## [1.1] í”¼ì²˜ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65368fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… feature specs loaded\n"
     ]
    }
   ],
   "source": [
    "\n",
    "DROP_COLS_RAW = [\"clicked\", \"ID\", \"seq\"]\n",
    "\n",
    "BASE_CAT_COLS = [\"gender\", \"age_group\", \"inventory_id\", \"day_of_week\", \"hour\", \"seq_first_num\", \"seq_last_num\"]\n",
    "\n",
    "CROSS_PAIRS = [\n",
    "    (\"inventory_id\", \"hour\"),\n",
    "    (\"inventory_id\", \"day_of_week\"),\n",
    "    (\"inventory_id\", \"age_group\"),\n",
    "    (\"gender\", \"age_group\"),\n",
    "]\n",
    "\n",
    "TE_COLS = [\"inventory_id\", \"inv_hour\", \"inv_dow\"]\n",
    "\n",
    "AGGS_TO_CREATE = {\n",
    "    \"history_a_1\": [\"mean\", \"std\"], \"history_a_2\": [\"mean\", \"std\"],\n",
    "    \"history_a_3\": [\"mean\", \"std\"], \"history_a_6\": [\"mean\", \"std\"],\n",
    "    \"feat_e_2\": [\"mean\", \"std\"], \"feat_e_3\": [\"mean\", \"std\"],\n",
    "    \"feat_c_8\": [\"mean\", \"std\"], \"feat_e_9\": [\"mean\", \"std\"],\n",
    "    \"feat_d_4\": [\"mean\", \"std\"],\n",
    "    \"l_feat_1\": [\"mean\", \"std\"], \"l_feat_2\": [\"mean\", \"std\"],\n",
    "    \"l_feat_5\": [\"mean\", \"std\"], \"l_feat_7\": [\"mean\", \"std\"],\n",
    "    \"l_feat_10\": [\"mean\", \"std\"], \"l_feat_15\": [\"mean\", \"std\"],\n",
    "}\n",
    "\n",
    "print(\"âœ… feature specs loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca913223",
   "metadata": {},
   "source": [
    "## [2] Global FE ìºì‹œ ìƒì„±/ë¡œë“œ (TRAIN_MODEë‹¹ 1íšŒ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7b57379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§Š FE cache not found -> building once...\n",
      "ðŸ“‚ Loading train: /home/konkukstat/python3/workspace/data/train.parquet\n",
      "ðŸ“‚ Loading test : /home/konkukstat/python3/workspace/data/test.parquet\n",
      "âœ… Raw Train: (10704179, 120) | Raw Test: (1527298, 119)\n",
      "ðŸ“Œ click-rate = 0.019075\n",
      "ðŸ› ï¸ add_seq_features ...\n",
      "ðŸ› ï¸ add_cat_crosses ...\n",
      "ðŸ› ï¸ add_count_features ...\n",
      "ðŸ’¾ Saved: /home/konkukstat/python3/workspace/data/_cache_fe/train_global_fe_full.parquet\n",
      "ðŸ’¾ Saved: /home/konkukstat/python3/workspace/data/_cache_fe/test_global_fe_full.parquet\n",
      "ðŸ§Š Loading FE cache ...\n",
      "âœ… Cached Train: (10704179, 132) | Cached Test: (1527298, 131)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "CACHE_DIR = os.path.join(CFG.DATA_PATH, CFG.CACHE_SUBDIR)\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "\n",
    "mode = str(CFG.TRAIN_MODE).lower().strip()\n",
    "TRAIN_FE_CACHE = os.path.join(CACHE_DIR, f\"train_global_fe_{mode}.parquet\")\n",
    "TEST_FE_CACHE  = os.path.join(CACHE_DIR, f\"test_global_fe_{mode}.parquet\")\n",
    "\n",
    "def get_train_file_by_mode(mode):\n",
    "    m = str(mode).lower().strip()\n",
    "    if m == \"full\":\n",
    "        return CFG.TRAIN_FULL_FILE\n",
    "    if m == \"10\":\n",
    "        return CFG.TRAIN_10_FILE\n",
    "    if m == \"50\":\n",
    "        return CFG.TRAIN_50_FILE\n",
    "    raise ValueError(\"CFG.TRAIN_MODE must be one of: '10', '50', 'full'\")\n",
    "\n",
    "def load_raw_train_test():\n",
    "    train_file = get_train_file_by_mode(CFG.TRAIN_MODE)\n",
    "    train_path = os.path.join(CFG.DATA_PATH, train_file)\n",
    "    full_path  = os.path.join(CFG.DATA_PATH, CFG.TRAIN_FULL_FILE)\n",
    "\n",
    "    if os.path.exists(train_path):\n",
    "        print(f\"ðŸ“‚ Loading train: {train_path}\")\n",
    "        train_df = pd.read_parquet(train_path).reset_index(drop=True)\n",
    "    else:\n",
    "        if not os.path.exists(full_path):\n",
    "            raise FileNotFoundError(f\"train file not found: {train_path} and full not found: {full_path}\")\n",
    "        frac = 0.10 if mode == \"10\" else (0.50 if mode == \"50\" else None)\n",
    "        print(f\"âš ï¸ {train_file} not found -> sample frac={frac} from {full_path}\")\n",
    "        train_df = pd.read_parquet(full_path).reset_index(drop=True)\n",
    "        if frac is not None:\n",
    "            train_df = train_df.sample(frac=frac, random_state=CFG.SAMPLE_SEED).reset_index(drop=True)\n",
    "\n",
    "    train_df[\"row_id\"] = np.arange(len(train_df))\n",
    "\n",
    "    test_path = os.path.join(CFG.DATA_PATH, CFG.TEST_FILE)\n",
    "    if not os.path.exists(test_path):\n",
    "        raise FileNotFoundError(f\"test file not found: {test_path}\")\n",
    "    print(f\"ðŸ“‚ Loading test : {test_path}\")\n",
    "    test_df = pd.read_parquet(test_path).reset_index(drop=True)\n",
    "\n",
    "    print(f\"âœ… Raw Train: {train_df.shape} | Raw Test: {test_df.shape}\")\n",
    "    return train_df, test_df\n",
    "\n",
    "def build_global_fe_and_cache():\n",
    "    train_df, test_df = load_raw_train_test()\n",
    "    if \"clicked\" not in train_df.columns:\n",
    "        raise KeyError(\"'clicked' not found in train\")\n",
    "\n",
    "    print(f\"ðŸ“Œ click-rate = {float(train_df['clicked'].mean()):.6f}\")\n",
    "\n",
    "    print(\"ðŸ› ï¸ add_seq_features ...\")\n",
    "    train_df, seq_fill = add_seq_features(train_df, \"train\", fill_stats=None)\n",
    "    test_df, _ = add_seq_features(test_df, \"test\", fill_stats=seq_fill)\n",
    "\n",
    "    # ë” ì´ìƒ seq ì•ˆ ì“°ë©´ ë“œëž\n",
    "    for df in (train_df, test_df):\n",
    "        if \"seq\" in df.columns:\n",
    "            df.drop(columns=[\"seq\"], inplace=True)\n",
    "    \n",
    "    print(\"ðŸ› ï¸ add_cat_crosses ...\")\n",
    "    train_df, test_df = add_cat_crosses(train_df, test_df, CROSS_PAIRS)\n",
    "\n",
    "    print(\"ðŸ› ï¸ add_count_features ...\")\n",
    "    count_cols = [c for c in BASE_CAT_COLS if c in train_df.columns and c in test_df.columns]\n",
    "    if len(count_cols) > 0:\n",
    "        train_df, test_df = add_count_features(train_df, test_df, count_cols, use_test_in_counts=True)\n",
    "\n",
    "    train_df.to_parquet(TRAIN_FE_CACHE, index=False)\n",
    "    test_df.to_parquet(TEST_FE_CACHE, index=False)\n",
    "    print(\"ðŸ’¾ Saved:\", TRAIN_FE_CACHE)\n",
    "    print(\"ðŸ’¾ Saved:\", TEST_FE_CACHE)\n",
    "\n",
    "    del train_df, test_df\n",
    "    gc.collect()\n",
    "\n",
    "if not (os.path.exists(TRAIN_FE_CACHE) and os.path.exists(TEST_FE_CACHE)):\n",
    "    print(\"ðŸ§Š FE cache not found -> building once...\")\n",
    "    build_global_fe_and_cache()\n",
    "else:\n",
    "    print(\"ðŸ§Š FE cache exists -> skip build\")\n",
    "\n",
    "print(\"ðŸ§Š Loading FE cache ...\")\n",
    "train_base = pd.read_parquet(TRAIN_FE_CACHE).reset_index(drop=True)\n",
    "test_base  = pd.read_parquet(TEST_FE_CACHE).reset_index(drop=True)\n",
    "print(f\"âœ… Cached Train: {train_base.shape} | Cached Test: {test_base.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7183cc3d",
   "metadata": {},
   "source": [
    "## [3] Main OOF Training Loop (seed 3ê°œ + GPU ì§€ì›) â€” seedë³„ pred ì €ìž¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b71656b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… GPUs detected: 2\n",
      "GPU 0: NVIDIA GeForce RTX 4090 (UUID: GPU-ec4c30bc-a6f3-154d-6fc1-05d9a9956795)\n",
      "GPU 1: NVIDIA GeForce RTX 4090 (UUID: GPU-e3160e3d-1847-13ee-9755-7b93df3dc8cf)\n",
      "\n",
      "\n",
      "========================================\n",
      "ðŸš€ Processing Seed: 42 | mode=FULL\n",
      "========================================\n",
      "ðŸ“Œ click-rate = 0.019075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_449002/4172781264.py:35: Pandas4Warning: For backward compatibility, 'str' dtypes are included by select_dtypes when 'object' dtype is specified. This behavior is deprecated and will be removed in a future version. Explicitly pass 'str' to `include` to select them, or to `exclude` to remove them and silence this warning.\n",
      "See https://pandas.pydata.org/docs/user_guide/migration-3-strings.html#string-migration-select-dtypes for details on how to write code that works with pandas 2 and 3.\n",
      "  auto_cat_cols = train_df[feature_cols_base].select_dtypes(include=[\"object\",\"category\"]).columns.tolist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… base features=131 | cat_cols=11\n",
      "  ðŸ” Fold 1/5\n",
      "     LogLoss=0.574741 | AP=0.083069 | Toss=0.359047\n",
      "  ðŸ” Fold 2/5\n",
      "     LogLoss=0.573751 | AP=0.082250 | Toss=0.358838\n",
      "  ðŸ” Fold 3/5\n",
      "     LogLoss=0.577117 | AP=0.082154 | Toss=0.358111\n",
      "  ðŸ” Fold 4/5\n",
      "     LogLoss=0.572230 | AP=0.083351 | Toss=0.359695\n",
      "  ðŸ” Fold 5/5\n",
      "     LogLoss=0.572642 | AP=0.083381 | Toss=0.359627\n",
      "âœ… OOF Summary: LogLoss=0.574096 | AP=0.082809 | Toss=0.359047\n",
      "ðŸ’¾ Pred saved: ./outputs/CB_full_seed42_pred.csv\n",
      "ðŸ’¾ OOF saved: ./outputs/CB_full_seed42_oof.csv\n",
      "\n",
      "========================================\n",
      "ðŸš€ Processing Seed: 106 | mode=FULL\n",
      "========================================\n",
      "ðŸ“Œ click-rate = 0.019075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_449002/4172781264.py:35: Pandas4Warning: For backward compatibility, 'str' dtypes are included by select_dtypes when 'object' dtype is specified. This behavior is deprecated and will be removed in a future version. Explicitly pass 'str' to `include` to select them, or to `exclude` to remove them and silence this warning.\n",
      "See https://pandas.pydata.org/docs/user_guide/migration-3-strings.html#string-migration-select-dtypes for details on how to write code that works with pandas 2 and 3.\n",
      "  auto_cat_cols = train_df[feature_cols_base].select_dtypes(include=[\"object\",\"category\"]).columns.tolist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… base features=131 | cat_cols=11\n",
      "  ðŸ” Fold 1/5\n",
      "     LogLoss=0.574018 | AP=0.083259 | Toss=0.359288\n",
      "  ðŸ” Fold 2/5\n",
      "     LogLoss=0.573211 | AP=0.083153 | Toss=0.359398\n",
      "  ðŸ” Fold 3/5\n",
      "     LogLoss=0.570663 | AP=0.083137 | Toss=0.359906\n",
      "  ðŸ” Fold 4/5\n",
      "     LogLoss=0.573184 | AP=0.081983 | Toss=0.358818\n",
      "  ðŸ” Fold 5/5\n",
      "     LogLoss=0.574103 | AP=0.083157 | Toss=0.359220\n",
      "âœ… OOF Summary: LogLoss=0.573036 | AP=0.082895 | Toss=0.359304\n",
      "ðŸ’¾ Pred saved: ./outputs/CB_full_seed106_pred.csv\n",
      "ðŸ’¾ OOF saved: ./outputs/CB_full_seed106_oof.csv\n",
      "\n",
      "========================================\n",
      "ðŸš€ Processing Seed: 1031 | mode=FULL\n",
      "========================================\n",
      "ðŸ“Œ click-rate = 0.019075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_449002/4172781264.py:35: Pandas4Warning: For backward compatibility, 'str' dtypes are included by select_dtypes when 'object' dtype is specified. This behavior is deprecated and will be removed in a future version. Explicitly pass 'str' to `include` to select them, or to `exclude` to remove them and silence this warning.\n",
      "See https://pandas.pydata.org/docs/user_guide/migration-3-strings.html#string-migration-select-dtypes for details on how to write code that works with pandas 2 and 3.\n",
      "  auto_cat_cols = train_df[feature_cols_base].select_dtypes(include=[\"object\",\"category\"]).columns.tolist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… base features=131 | cat_cols=11\n",
      "  ðŸ” Fold 1/5\n",
      "     LogLoss=0.573489 | AP=0.082680 | Toss=0.359105\n",
      "  ðŸ” Fold 2/5\n",
      "     LogLoss=0.573164 | AP=0.082047 | Toss=0.358854\n",
      "  ðŸ” Fold 3/5\n",
      "     LogLoss=0.574955 | AP=0.082705 | Toss=0.358822\n",
      "  ðŸ” Fold 4/5\n",
      "     LogLoss=0.567496 | AP=0.082995 | Toss=0.360478\n",
      "  ðŸ” Fold 5/5\n",
      "     LogLoss=0.574900 | AP=0.083733 | Toss=0.359347\n",
      "âœ… OOF Summary: LogLoss=0.572801 | AP=0.082799 | Toss=0.359304\n",
      "ðŸ’¾ Pred saved: ./outputs/CB_full_seed1031_pred.csv\n",
      "ðŸ’¾ OOF saved: ./outputs/CB_full_seed1031_oof.csv\n",
      "âœ… Done. pred files: ['./outputs/CB_full_seed42_pred.csv', './outputs/CB_full_seed106_pred.csv', './outputs/CB_full_seed1031_pred.csv']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prediction_files = []\n",
    "oof_files = []\n",
    "seed_test_preds = {}\n",
    "seed_oof_preds  = {}\n",
    "seed_best_iters = {}\n",
    "\n",
    "if CFG.USE_GPU:\n",
    "    print_gpu_info()\n",
    "\n",
    "for seed in CFG.SEEDS:\n",
    "    print(f\"\\n{'='*40}\\nðŸš€ Processing Seed: {seed} | mode={CFG.TRAIN_MODE}\\n{'='*40}\")\n",
    "    seed_everything(seed)\n",
    "\n",
    "    train_df = train_base.copy()\n",
    "    test_df  = test_base.copy()\n",
    "\n",
    "    y_all = train_df[\"clicked\"].values.astype(int)\n",
    "    print(f\"ðŸ“Œ click-rate = {float(y_all.mean()):.6f}\")\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=CFG.N_SPLITS, shuffle=True, random_state=seed)\n",
    "    folds_list = list(skf.split(train_df, y_all))\n",
    "\n",
    "    train_df, test_df = add_oof_target_encoding(\n",
    "        train_df, test_df, y_all,\n",
    "        cols=TE_COLS,\n",
    "        folds=folds_list,\n",
    "        smoothing=20.0,\n",
    "        noise=0.0,\n",
    "        seed=seed\n",
    "    )\n",
    "\n",
    "    DROP_COLS = [c for c in DROP_COLS_RAW if c in train_df.columns]\n",
    "    feature_cols_base = [c for c in train_df.columns if c not in DROP_COLS + [\"row_id\"]]\n",
    "\n",
    "    auto_cat_cols = train_df[feature_cols_base].select_dtypes(include=[\"object\",\"category\"]).columns.tolist()\n",
    "    cat_cols_base = sorted(list(set([c for c in BASE_CAT_COLS if c in feature_cols_base] + auto_cat_cols)))\n",
    "    cat_cols_base = [c for c in cat_cols_base if c in test_df.columns]\n",
    "\n",
    "    print(f\"âœ… base features={len(feature_cols_base)} | cat_cols={len(cat_cols_base)}\")\n",
    "\n",
    "    oof_pred = np.zeros(len(train_df), dtype=float)\n",
    "    test_pred_folds = []\n",
    "    best_iters = []\n",
    "\n",
    "    cb_params = dict(\n",
    "        loss_function=\"Logloss\",\n",
    "        eval_metric=\"Logloss\",\n",
    "        iterations=CFG.CB_ITERATIONS,\n",
    "        learning_rate=CFG.CB_LEARNING_RATE,\n",
    "        depth=CFG.CB_DEPTH,\n",
    "        l2_leaf_reg=CFG.CB_L2,\n",
    "        random_strength=CFG.CB_RANDOM_STRENGTH,\n",
    "        auto_class_weights=\"Balanced\",\n",
    "        bootstrap_type=\"Bernoulli\",\n",
    "        subsample=CFG.CB_SUBSAMPLE,\n",
    "        random_state=seed,\n",
    "        verbose=False,\n",
    "        allow_writing_files=False,\n",
    "    )\n",
    "\n",
    "    if CFG.USE_GPU:\n",
    "        cb_params.update(dict(task_type=\"GPU\", devices=CFG.GPU_DEVICES))\n",
    "        # GPUì—ì„œëŠ” rsm ë¯¸ì§€ì› -> ë„£ì§€ ì•ŠìŒ\n",
    "    else:\n",
    "        cb_params.update(dict(task_type=\"CPU\", rsm=CFG.CB_RSM_CPU))\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(folds_list, 1):\n",
    "        print(f\"  ðŸ” Fold {fold}/{CFG.N_SPLITS}\")\n",
    "\n",
    "        X_tr = train_df.iloc[tr_idx].copy()\n",
    "        y_tr = y_all[tr_idx]\n",
    "        X_va = train_df.iloc[va_idx].copy()\n",
    "        y_va = y_all[va_idx]\n",
    "        X_te = test_df.copy()\n",
    "\n",
    "        # fold-safe groupby stats\n",
    "        group_key = \"inventory_id\"\n",
    "        groupby_cols = []\n",
    "        if group_key in X_tr.columns:\n",
    "            agg_dict = {k:v for k,v in AGGS_TO_CREATE.items() if k in X_tr.columns}\n",
    "            if len(agg_dict) > 0:\n",
    "                stats = make_groupby_stats(X_tr, group_key, agg_dict)\n",
    "                X_tr = merge_groupby_stats(X_tr, stats, group_key, fill_from_df=X_tr)\n",
    "                X_va = merge_groupby_stats(X_va, stats, group_key, fill_from_df=X_tr)\n",
    "                X_te = merge_groupby_stats(X_te, stats, group_key, fill_from_df=X_tr)\n",
    "                groupby_cols = [c for c in stats.columns if c != group_key]\n",
    "\n",
    "        feature_cols_fold = feature_cols_base + groupby_cols\n",
    "        cat_cols_fold = [c for c in cat_cols_base if c in feature_cols_fold]\n",
    "\n",
    "        # íƒ€ìž…/ê²°ì¸¡ ì•ˆì •í™”\n",
    "        for col in feature_cols_fold:\n",
    "            if col in cat_cols_fold:\n",
    "                X_tr[col] = X_tr[col].astype(str).fillna(\"unknown\")\n",
    "                X_va[col] = X_va[col].astype(str).fillna(\"unknown\")\n",
    "                X_te[col] = X_te[col].astype(str).fillna(\"unknown\")\n",
    "            else:\n",
    "                X_tr[col] = pd.to_numeric(X_tr[col], errors=\"coerce\")\n",
    "                X_va[col] = pd.to_numeric(X_va[col], errors=\"coerce\")\n",
    "                X_te[col] = pd.to_numeric(X_te[col], errors=\"coerce\")\n",
    "                m = X_tr[col].mean()\n",
    "                fv = float(m) if np.isfinite(m) else 0.0\n",
    "                X_tr[col] = X_tr[col].fillna(fv)\n",
    "                X_va[col] = X_va[col].fillna(fv)\n",
    "                X_te[col] = X_te[col].fillna(fv)\n",
    "\n",
    "        model = cb.CatBoostClassifier(**cb_params, cat_features=cat_cols_fold)\n",
    "        model.fit(\n",
    "            X_tr[feature_cols_fold], y_tr,\n",
    "            eval_set=(X_va[feature_cols_fold], y_va),\n",
    "            early_stopping_rounds=100,\n",
    "            use_best_model=True,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        best_it = model.get_best_iteration()\n",
    "        if best_it is None:\n",
    "            best_it = cb_params.get(\"iterations\", 2000)\n",
    "        best_iters.append(int(best_it))\n",
    "\n",
    "        va_pred = model.predict_proba(X_va[feature_cols_fold])[:, 1]\n",
    "        te_pred = model.predict_proba(X_te[feature_cols_fold])[:, 1]\n",
    "\n",
    "        oof_pred[va_idx] = va_pred\n",
    "        test_pred_folds.append(te_pred)\n",
    "\n",
    "        ll = float(log_loss(y_va, np.clip(va_pred, EPS, 1-EPS)))\n",
    "        ap = float(average_precision_score(y_va, np.clip(va_pred, EPS, 1-EPS)))\n",
    "        ts = float(toss_score(y_va, va_pred))\n",
    "        print(f\"     LogLoss={ll:.6f} | AP={ap:.6f} | Toss={ts:.6f}\")\n",
    "\n",
    "        del model, X_tr, X_va, X_te\n",
    "        gc.collect()\n",
    "\n",
    "    # OOF Summary\n",
    "    oof_clip = np.clip(oof_pred, EPS, 1-EPS)\n",
    "    val_ll = float(log_loss(y_all, oof_clip))\n",
    "    val_ap = float(average_precision_score(y_all, oof_clip))\n",
    "    val_ts = float(toss_score(y_all, oof_clip))\n",
    "    print(f\"âœ… OOF Summary: LogLoss={val_ll:.6f} | AP={val_ap:.6f} | Toss={val_ts:.6f}\")\n",
    "\n",
    "    # fold í‰ê·  test pred\n",
    "    test_pred = np.mean(np.vstack(test_pred_folds), axis=0)\n",
    "\n",
    "    # save\n",
    "    os.makedirs(CFG.OUTPUT_DIR, exist_ok=True)\n",
    "    pred_file = os.path.join(CFG.OUTPUT_DIR, f\"{CFG.OUTPUT_PREFIX}_{mode}_seed{seed}_pred.csv\")\n",
    "    pd.DataFrame({\"ID\": test_df[\"ID\"].values, \"clicked\": test_pred}).to_csv(pred_file, index=False)\n",
    "    prediction_files.append(pred_file)\n",
    "    print(\"ðŸ’¾ Pred saved:\", pred_file)\n",
    "\n",
    "    oof_file = os.path.join(CFG.OUTPUT_DIR, f\"{CFG.OUTPUT_PREFIX}_{mode}_seed{seed}_oof.csv\")\n",
    "    pd.DataFrame({\"row_id\": train_df[\"row_id\"].values, \"y_true\": y_all, \"oof_pred\": oof_pred}).to_csv(oof_file, index=False)\n",
    "    oof_files.append(oof_file)\n",
    "    print(\"ðŸ’¾ OOF saved:\", oof_file)\n",
    "\n",
    "    seed_test_preds[seed] = test_pred\n",
    "    seed_oof_preds[seed]  = oof_pred\n",
    "    seed_best_iters[seed] = best_iters\n",
    "\n",
    "    del train_df, test_df\n",
    "    gc.collect()\n",
    "\n",
    "print(\"âœ… Done. pred files:\", prediction_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02b50d9",
   "metadata": {},
   "source": [
    "## [3.1] Full-train Refit (seedë³„ best_iter í‰ê· ) + seedë³„ test ì˜ˆì¸¡ ì €ìž¥\n",
    "\n",
    "- [3]ì—ì„œ ê° foldì˜ `best_iteration`ì„ ëª¨ì•„ í‰ê· ìœ¼ë¡œ `refit_iters`ë¥¼ ì •í•˜ê³ ,\n",
    "  ê°™ì€ í”¼ì²˜ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ **ì „ì²´ train**ì— ë‹¤ì‹œ í•™ìŠµí•œ ë’¤ testë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.\n",
    "- foldë³„ test ì˜ˆì¸¡ í‰ê· ë³´ë‹¤ **ì¼ë°˜ì ìœ¼ë¡œ ë” ê°•í•œ ìµœì¢… ëª¨ë¸**ì´ ë©ë‹ˆë‹¤.\n",
    "- (ì„ íƒ) refit ë‹¨ê³„ì—ì„œëŠ” Target Encodingì„ **ì „ì²´ train ê¸°ì¤€ìœ¼ë¡œ ìž¬ê³„ì‚°**í•´ì„œ ì ìš©í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbf30ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§  Refit seed=42 | refit_iters=1482 | mode=FULL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_449002/1363397661.py:42: Pandas4Warning: For backward compatibility, 'str' dtypes are included by select_dtypes when 'object' dtype is specified. This behavior is deprecated and will be removed in a future version. Explicitly pass 'str' to `include` to select them, or to `exclude` to remove them and silence this warning.\n",
      "See https://pandas.pydata.org/docs/user_guide/migration-3-strings.html#string-migration-select-dtypes for details on how to write code that works with pandas 2 and 3.\n",
      "  auto_cat_cols = train_df[feature_cols_base].select_dtypes(include=[\"object\",\"category\"]).columns.tolist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ Refit pred saved: ./outputs/CB_full_seed42_refit_pred.csv\n",
      "\n",
      "ðŸ§  Refit seed=106 | refit_iters=1530 | mode=FULL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_449002/1363397661.py:42: Pandas4Warning: For backward compatibility, 'str' dtypes are included by select_dtypes when 'object' dtype is specified. This behavior is deprecated and will be removed in a future version. Explicitly pass 'str' to `include` to select them, or to `exclude` to remove them and silence this warning.\n",
      "See https://pandas.pydata.org/docs/user_guide/migration-3-strings.html#string-migration-select-dtypes for details on how to write code that works with pandas 2 and 3.\n",
      "  auto_cat_cols = train_df[feature_cols_base].select_dtypes(include=[\"object\",\"category\"]).columns.tolist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ Refit pred saved: ./outputs/CB_full_seed106_refit_pred.csv\n",
      "\n",
      "ðŸ§  Refit seed=1031 | refit_iters=1546 | mode=FULL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_449002/1363397661.py:42: Pandas4Warning: For backward compatibility, 'str' dtypes are included by select_dtypes when 'object' dtype is specified. This behavior is deprecated and will be removed in a future version. Explicitly pass 'str' to `include` to select them, or to `exclude` to remove them and silence this warning.\n",
      "See https://pandas.pydata.org/docs/user_guide/migration-3-strings.html#string-migration-select-dtypes for details on how to write code that works with pandas 2 and 3.\n",
      "  auto_cat_cols = train_df[feature_cols_base].select_dtypes(include=[\"object\",\"category\"]).columns.tolist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ Refit pred saved: ./outputs/CB_full_seed1031_refit_pred.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Full-train refit per seed (uses best_iters from [3]) ---\n",
    "\n",
    "seed_test_preds_refit = {}\n",
    "\n",
    "def compute_full_target_encoding(train_df, test_df, y, cols, smoothing=20.0):\n",
    "    \"\"\"ì „ì²´ train ê¸°ì¤€ TEë¥¼ ê³„ì‚°í•´ì„œ train/testì— ë™ì¼ ì ìš© (refit ë‹¨ê³„ìš©).\"\"\"\n",
    "    prior = float(np.mean(y))\n",
    "    out_tr = train_df.copy()\n",
    "    out_te = test_df.copy()\n",
    "    for col in cols:\n",
    "        if col not in out_tr.columns or col not in out_te.columns:\n",
    "            continue\n",
    "        grp = out_tr.groupby(col)[\"clicked\"].agg([\"count\",\"mean\"]).reset_index()\n",
    "        grp[\"te\"] = (grp[\"count\"]*grp[\"mean\"] + smoothing*prior) / (grp[\"count\"] + smoothing)\n",
    "        mapping = dict(zip(grp[col].values, grp[\"te\"].values))\n",
    "        out_tr[f\"te_{col}\"] = out_tr[col].map(mapping).fillna(prior).astype(float)\n",
    "        out_te[f\"te_{col}\"] = out_te[col].map(mapping).fillna(prior).astype(float)\n",
    "    return out_tr, out_te\n",
    "\n",
    "if \"seed_best_iters\" not in globals():\n",
    "    raise RuntimeError(\"Run [3] first. seed_best_iters not found.\")\n",
    "\n",
    "for seed in CFG.SEEDS:\n",
    "    if seed not in seed_best_iters:\n",
    "        print(f\"âš ï¸ seed {seed}: best_iters not found -> skip refit\")\n",
    "        continue\n",
    "\n",
    "    best_iters = seed_best_iters[seed]\n",
    "    refit_iters = int(np.clip(np.mean(best_iters), CFG.REFIT_ITERS_MIN, CFG.REFIT_ITERS_MAX))\n",
    "    print(f\"\\nðŸ§  Refit seed={seed} | refit_iters={refit_iters} | mode={CFG.TRAIN_MODE}\")\n",
    "\n",
    "    train_df = train_base.copy()\n",
    "    test_df  = test_base.copy()\n",
    "    y_all = train_df[\"clicked\"].values.astype(int)\n",
    "\n",
    "    # (ì„ íƒ) ìµœì¢… refitì—ì„œëŠ” TEë¥¼ full-train ê¸°ì¤€ìœ¼ë¡œ ìž¬ê³„ì‚°\n",
    "    if CFG.REFIT_RECOMPUTE_TE:\n",
    "        train_df, test_df = compute_full_target_encoding(train_df, test_df, y_all, TE_COLS, smoothing=20.0)\n",
    "\n",
    "    DROP_COLS = [c for c in DROP_COLS_RAW if c in train_df.columns]\n",
    "    feature_cols_base = [c for c in train_df.columns if c not in DROP_COLS + [\"row_id\"]]\n",
    "    auto_cat_cols = train_df[feature_cols_base].select_dtypes(include=[\"object\",\"category\"]).columns.tolist()\n",
    "    cat_cols_base = sorted(list(set([c for c in BASE_CAT_COLS if c in feature_cols_base] + auto_cat_cols)))\n",
    "    cat_cols_base = [c for c in cat_cols_base if c in test_df.columns]\n",
    "\n",
    "    # full ê¸°ì¤€ groupby stats\n",
    "    group_key = \"inventory_id\"\n",
    "    groupby_cols = []\n",
    "    if group_key in train_df.columns:\n",
    "        agg_dict = {k:v for k,v in AGGS_TO_CREATE.items() if k in train_df.columns}\n",
    "        if len(agg_dict) > 0:\n",
    "            stats = make_groupby_stats(train_df, group_key, agg_dict)\n",
    "            train_df = merge_groupby_stats(train_df, stats, group_key, fill_from_df=train_df)\n",
    "            test_df  = merge_groupby_stats(test_df,  stats, group_key, fill_from_df=train_df)\n",
    "            groupby_cols = [c for c in stats.columns if c != group_key]\n",
    "\n",
    "    feature_cols = feature_cols_base + groupby_cols\n",
    "    cat_cols = [c for c in cat_cols_base if c in feature_cols]\n",
    "\n",
    "    # íƒ€ìž…/ê²°ì¸¡ ì•ˆì •í™”\n",
    "    for col in feature_cols:\n",
    "        if col in cat_cols:\n",
    "            train_df[col] = train_df[col].astype(str).fillna(\"unknown\")\n",
    "            test_df[col]  = test_df[col].astype(str).fillna(\"unknown\")\n",
    "        else:\n",
    "            train_df[col] = pd.to_numeric(train_df[col], errors=\"coerce\")\n",
    "            test_df[col]  = pd.to_numeric(test_df[col], errors=\"coerce\")\n",
    "            m = train_df[col].mean()\n",
    "            fv = float(m) if np.isfinite(m) else 0.0\n",
    "            train_df[col] = train_df[col].fillna(fv)\n",
    "            test_df[col]  = test_df[col].fillna(fv)\n",
    "\n",
    "    cb_params = dict(\n",
    "        loss_function=\"Logloss\",\n",
    "        eval_metric=\"Logloss\",\n",
    "        iterations=refit_iters,\n",
    "        learning_rate=CFG.CB_LEARNING_RATE,\n",
    "        depth=CFG.CB_DEPTH,\n",
    "        l2_leaf_reg=CFG.CB_L2,\n",
    "        random_strength=CFG.CB_RANDOM_STRENGTH,\n",
    "        auto_class_weights=\"Balanced\",\n",
    "        bootstrap_type=\"Bernoulli\",\n",
    "        subsample=CFG.CB_SUBSAMPLE,\n",
    "        random_state=seed,\n",
    "        verbose=False,\n",
    "        allow_writing_files=False,\n",
    "    )\n",
    "    if CFG.USE_GPU:\n",
    "        cb_params.update(dict(task_type=\"GPU\", devices=CFG.GPU_DEVICES))\n",
    "    else:\n",
    "        cb_params.update(dict(task_type=\"CPU\", rsm=CFG.CB_RSM_CPU))\n",
    "\n",
    "    model = cb.CatBoostClassifier(**cb_params, cat_features=cat_cols)\n",
    "    model.fit(train_df[feature_cols], y_all, verbose=False)\n",
    "    pred = model.predict_proba(test_df[feature_cols])[:, 1].astype(float)\n",
    "\n",
    "    os.makedirs(CFG.OUTPUT_DIR, exist_ok=True)\n",
    "    refit_file = os.path.join(CFG.OUTPUT_DIR, f\"{CFG.OUTPUT_PREFIX}_{mode}_seed{seed}_refit_pred.csv\")\n",
    "    pd.DataFrame({\"ID\": test_df[\"ID\"].values, \"clicked\": pred}).to_csv(refit_file, index=False)\n",
    "    print(\"ðŸ’¾ Refit pred saved:\", refit_file)\n",
    "\n",
    "    seed_test_preds_refit[seed] = pred\n",
    "    del model, train_df, test_df\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9605e487",
   "metadata": {},
   "source": [
    "## [4] SoftVoting ì•™ìƒë¸” + Test ê¸°ë°˜ í‰ê°€(ì˜µì…˜)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36e2fcec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ SoftVoting saved: ./outputs/CB_full_softvoting_pred.csv\n",
      "â„¹ï¸ Test labels not provided -> skip test evaluation.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# SoftVoting\n",
    "# prefer refit preds if available\n",
    "pred_source = seed_test_preds_refit if ('seed_test_preds_refit' in globals() and len(seed_test_preds_refit)>0) else seed_test_preds\n",
    "seeds = list(pred_source.keys())\n",
    "if len(seeds) == 0:\n",
    "    raise RuntimeError(\"No seed predictions found. Run [3] first.\")\n",
    "\n",
    "if CFG.SEED_WEIGHTS is None:\n",
    "    w = np.ones(len(seeds), dtype=float)\n",
    "else:\n",
    "    w = np.array([float(CFG.SEED_WEIGHTS.get(s, 1.0)) for s in seeds], dtype=float)\n",
    "w = w / w.sum()\n",
    "\n",
    "pred_mat = np.vstack([pred_source[s] for s in seeds])  # (n_seeds, n_test)\n",
    "ens_pred = (pred_mat.T @ w).astype(float)\n",
    "\n",
    "ens_file = os.path.join(CFG.OUTPUT_DIR, f\"{CFG.OUTPUT_PREFIX}_{mode}_softvoting_pred.csv\")\n",
    "pd.DataFrame({\"ID\": test_base[\"ID\"].values, \"clicked\": ens_pred}).to_csv(ens_file, index=False)\n",
    "print(\"ðŸ’¾ SoftVoting saved:\", ens_file)\n",
    "\n",
    "# Optional test evaluation\n",
    "def load_test_labels():\n",
    "    if \"clicked\" in test_base.columns:\n",
    "        return test_base[[\"ID\",\"clicked\"]].copy()\n",
    "    if CFG.TEST_LABEL_FILE is None:\n",
    "        return None\n",
    "    path = CFG.TEST_LABEL_FILE\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"TEST_LABEL_FILE not found: {path}\")\n",
    "    if path.endswith(\".parquet\"):\n",
    "        lab = pd.read_parquet(path)\n",
    "    else:\n",
    "        lab = pd.read_csv(path)\n",
    "    if \"ID\" not in lab.columns or \"clicked\" not in lab.columns:\n",
    "        raise KeyError(\"TEST_LABEL_FILE must include columns: ID, clicked\")\n",
    "    return lab[[\"ID\",\"clicked\"]].copy()\n",
    "\n",
    "labels = load_test_labels()\n",
    "if labels is None:\n",
    "    print(\"â„¹ï¸ Test labels not provided -> skip test evaluation.\")\n",
    "else:\n",
    "    merged = pd.DataFrame({\"ID\": test_base[\"ID\"].values, \"pred\": ens_pred}).merge(labels, on=\"ID\", how=\"inner\")\n",
    "    y_true = merged[\"clicked\"].values.astype(int)\n",
    "    y_pred = np.clip(merged[\"pred\"].values.astype(float), EPS, 1-EPS)\n",
    "    ap = float(average_precision_score(y_true, y_pred))\n",
    "    ll = float(log_loss(y_true, y_pred))\n",
    "    ts = float(toss_score(y_true, y_pred))\n",
    "    print(f\"âœ… [TEST EVAL] AP={ap:.6f} | LogLoss={ll:.6f} | Toss={ts:.6f} | n={len(merged)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
